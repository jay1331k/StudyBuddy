import os
from dotenv import load_dotenv
import google.generativeai as genai
import json

load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

def get_explanation(prompt):
    """
    Sends a prompt to the LLM (Gemini) and returns the explanation.

    Args:
        prompt (str): The prompt to send to the LLM.

    Returns:
        str: The explanation generated by the LLM.
    """

    model = genai.GenerativeModel(model_name='gemini-1.5-flash')
    completion = model.generate_content(
        prompt
    )

    try:
        explanation_data = json.loads(completion.text.strip())
        # Format the explanation based on the JSON structure defined in roadmap.py
        explanation = f"""
        **Introduction:**
        {explanation_data['introduction']}

        **Definition:**
        {explanation_data['definition']}

        **Analogy:**
        {explanation_data['analogy']}

        **Examples:**
        {', '.join(explanation_data['examples'])}

        **MCQ Questions:**
        """
        for question in explanation_data['mcq_questions']:
            explanation += f"""
            {question['question']}
            a) {question['options'][0]}
            b) {question['options'][1]}
            c) {question['options'][2]}
            d) {question['options'][3]}

            **Answer:** {question['answer']}
            """

        return explanation

    except json.JSONDecodeError:
        # Handle cases where the LLM response is not in the expected JSON format
        return completion.text